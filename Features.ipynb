{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns ## Beautiful Plots :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import operator\n",
    "import datetime\n",
    "from collections import Counter\n",
    "from nltk import ngrams\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Random_Acts_Of_Pizza(object):\n",
    "    \"\"\"\n",
    "    This class takes in a dataframe from \"Random Acts Of Pizza\"\n",
    "    and creates a set of features for each requests present in\n",
    "    the data. The features can be explicitly accessed with the \n",
    "    help of methods of this class.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,dataframe):\n",
    "        \"\"\"\n",
    "        The input is a dataframe. We have explicitly used\n",
    "        data provided from the Kaggle competition named as\n",
    "        Random Acts Of Pizza.\n",
    "        Link : https://www.kaggle.com/c/random-acts-of-pizza/data\n",
    "        \"\"\"\n",
    "        self.df = dataframe\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self.df.info())\n",
    "    \n",
    "    def get_narrative(self,col,narrative):\n",
    "        \"\"\"\n",
    "        Takes in input as the column and a lexicon for\n",
    "        the narrative. The lexicon is in the form of a \n",
    "        dictionary where key in the narrative and value\n",
    "        is a string containing all words relating to the\n",
    "        narrative.\n",
    "        Outputs a list containing narrative score for\n",
    "        each request\n",
    "        \"\"\"\n",
    "        request_narrative,narration = [],[]\n",
    "        for request in self.df[col]:\n",
    "            word_count = {'Money':0,'Job':0,'Student':0,'Family':0,'Craving':0}\n",
    "            n = 0\n",
    "            for word in request.split():\n",
    "                for lexicon in narrative:\n",
    "                    if word in narrative[lexicon]:\n",
    "                        word_count[lexicon] += 1\n",
    "            narration.append(max(word_count.iteritems(), key=operator.itemgetter(1))[0])\n",
    "        print 'Use get_dummies to encode the features as binary'\n",
    "        return narration\n",
    "    \n",
    "    def get_politeness(self,col,polite_words):\n",
    "        \"\"\"\n",
    "        Takes in input as the column for which politeness\n",
    "        needs to be calculated.\n",
    "        Output is a list of floats for each request where\n",
    "        each float corresponds to the politeness score for\n",
    "        each request.\n",
    "        \"\"\"\n",
    "        count,politeness = 0,[]\n",
    "        for request in self.df[col]:\n",
    "            count += 1\n",
    "            request_ngrams = []\n",
    "            for grams in ngrams(request.split(),3):\n",
    "                request_ngrams.append(' '.join(grams))\n",
    "            for grams in ngrams(request.split(),2):\n",
    "                request_ngrams.append(' '.join(grams))\n",
    "            request_words = set(request.split())\n",
    "            request_ngrams = set(request_ngrams)\n",
    "            num = len(request_words.intersection(set(polite_words))) +\\\n",
    "            len(request_ngrams.intersection(set(polite_words)))\n",
    "            try:\n",
    "                politeness.append(float(num)/len(request_words))\n",
    "            except:\n",
    "                politeness.append(0.0)\n",
    "        print 'Total Number of request parsed: ',count\n",
    "        return politeness\n",
    "    \n",
    "    def get_length(self,col):\n",
    "        \"\"\"\n",
    "        Takes input as the column name(for the request)\n",
    "        Outputs the length \n",
    "        \"\"\"\n",
    "        return [len(x.split()) for x in self.df[col]]\n",
    "    \n",
    "    def get_karma(self):\n",
    "        \"\"\"\n",
    "        Calculate the karma score for each user of the\n",
    "        RAOP.\n",
    "        Output is a list of karma score for each requester.\n",
    "        \"\"\"\n",
    "        karma = self.df['requester_upvotes_plus_downvotes_at_request']+\\\n",
    "        self.df['requester_upvotes_plus_downvotes_at_retrieval']\n",
    "        return karma\n",
    "    \n",
    "    def get_score(self):\n",
    "        \"\"\"\n",
    "        Calculates the score of each user of RAOP.\n",
    "        Output is a list of score for each user.\n",
    "        \"\"\"\n",
    "        score = self.df['requester_upvotes_minus_downvotes_at_request']+\\\n",
    "        self.df['requester_upvotes_minus_downvotes_at_retrieval']\n",
    "        return score\n",
    "    \n",
    "    def get_evidentiality(self,col):\n",
    "        \"\"\"\n",
    "        We count the occur- rences of http links, image links,\n",
    "        and “proof”/“prove”\n",
    "        Returns a list of number of urls for each request.\n",
    "        \"\"\"\n",
    "        urls = []\n",
    "        for text in self.df[col]:\n",
    "            url = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', text)\n",
    "            urls.append(len(url))\n",
    "        return urls\n",
    "    \n",
    "    def get_complexity(self,col):\n",
    "        \"\"\"\n",
    "        Takes input as the column of request and calculate\n",
    "        the complexity score given by Flesch-Kincaid Grade \n",
    "        Level.\n",
    "        Returns a list of complexity score for each request.\n",
    "        \"\"\"\n",
    "        grade_level = []\n",
    "        syl = set(['a','e','i','o','u'])\n",
    "        for text in self.df[col]:\n",
    "            sent_cnt = len(text.split('.'))\n",
    "            words = re.sub(\"[\"+'!\"#$%&\\'()*+.,-/:;<=>?@[\\\\]^_`{|}~'+\"]\", \" \", text).split()\n",
    "            syl_count = 0\n",
    "            for word in words:\n",
    "                for letter in list(word):\n",
    "                    if letter in syl:\n",
    "                        syl_count += 1\n",
    "            grade_level.append(Flesch_reading_ease(total_sentences = sent_cnt,total_words = len(words),\\\n",
    "                                                   total_sylabls=syl_count))\n",
    "        return grade_level\n",
    "    \n",
    "    def spell_check_score(self,col):\n",
    "        \"\"\"\n",
    "        We further use a spell-checker to identify misspelled \n",
    "        words in the request text [10]. In other contexts \n",
    "        (e.g. Kickstarter), spelling errors have been found to\n",
    "        have a negative impact on funding success.\n",
    "        \n",
    "        Input is the column of request.\n",
    "        Returns a list of spelling check score for each\n",
    "        request\n",
    "        \"\"\"\n",
    "        spell_errors = []\n",
    "        for text in self.df[col]:\n",
    "            spl_err = 0\n",
    "            words = re.sub(\"[\"+'!\"#$%&\\'()*+.,-/:;<=>?@[\\\\]^_`{|}~'+\"]\", \" \", text).split()\n",
    "            if len(words):\n",
    "                for word in words:\n",
    "                    if correction(word)!= word: \n",
    "                        spl_err += 1\n",
    "                spell_errors.append(float(spl_err)/len(words))\n",
    "            else:\n",
    "                spell_errors.append(0)\n",
    "        return spell_errors\n",
    "    \n",
    "    def first_half_of_month(self,col):\n",
    "        \"\"\"\n",
    "        Input is the column containing the timestamp\n",
    "        Returns the day of the timestamp for a request\n",
    "        \"\"\"\n",
    "        return [datetime.datetime.fromtimestamp(int(timestamp)).day \\\n",
    "                for timestamp in self.df[col]]\n",
    "    \n",
    "    def get_popularity(self,col):\n",
    "        \"\"\"\n",
    "        Input is the column containing the total upvotes\n",
    "        the request got at time of retrieval\n",
    "        \"\"\"\n",
    "        return self.df[col]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_json('../Desktop/train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4040 entries, 0 to 4039\n",
      "Data columns (total 43 columns):\n",
      "giver_username_if_known                                 4040 non-null object\n",
      "number_of_downvotes_of_request_at_retrieval             4040 non-null int64\n",
      "number_of_upvotes_of_request_at_retrieval               4040 non-null int64\n",
      "post_was_edited                                         4040 non-null int64\n",
      "request_id                                              4040 non-null object\n",
      "request_number_of_comments_at_retrieval                 4040 non-null int64\n",
      "request_text                                            4040 non-null object\n",
      "request_text_edit_aware                                 4040 non-null object\n",
      "request_title                                           4040 non-null object\n",
      "requester_account_age_in_days_at_request                4040 non-null float64\n",
      "requester_account_age_in_days_at_retrieval              4040 non-null float64\n",
      "requester_days_since_first_post_on_raop_at_request      4040 non-null float64\n",
      "requester_days_since_first_post_on_raop_at_retrieval    4040 non-null float64\n",
      "requester_number_of_comments_at_request                 4040 non-null int64\n",
      "requester_number_of_comments_at_retrieval               4040 non-null int64\n",
      "requester_number_of_comments_in_raop_at_request         4040 non-null int64\n",
      "requester_number_of_comments_in_raop_at_retrieval       4040 non-null int64\n",
      "requester_number_of_posts_at_request                    4040 non-null int64\n",
      "requester_number_of_posts_at_retrieval                  4040 non-null int64\n",
      "requester_number_of_posts_on_raop_at_request            4040 non-null int64\n",
      "requester_number_of_posts_on_raop_at_retrieval          4040 non-null int64\n",
      "requester_number_of_subreddits_at_request               4040 non-null int64\n",
      "requester_received_pizza                                4040 non-null bool\n",
      "requester_subreddits_at_request                         4040 non-null object\n",
      "requester_upvotes_minus_downvotes_at_request            4040 non-null int64\n",
      "requester_upvotes_minus_downvotes_at_retrieval          4040 non-null int64\n",
      "requester_upvotes_plus_downvotes_at_request             4040 non-null int64\n",
      "requester_upvotes_plus_downvotes_at_retrieval           4040 non-null int64\n",
      "requester_user_flair                                    994 non-null object\n",
      "requester_username                                      4040 non-null object\n",
      "unix_timestamp_of_request                               4040 non-null int64\n",
      "unix_timestamp_of_request_utc                           4040 non-null int64\n",
      "narrative_topics_Craving                                4040 non-null uint8\n",
      "narrative_topics_Family                                 4040 non-null uint8\n",
      "narrative_topics_Job                                    4040 non-null uint8\n",
      "narrative_topics_Money                                  4040 non-null uint8\n",
      "narrative_topics_Student                                4040 non-null uint8\n",
      "politeness                                              4040 non-null float64\n",
      "request_length                                          4040 non-null int64\n",
      "karma                                                   4040 non-null int64\n",
      "scores                                                  4040 non-null int64\n",
      "trust                                                   4040 non-null int64\n",
      "complexity                                              4040 non-null float64\n",
      "dtypes: bool(1), float64(6), int64(23), object(8), uint8(5)\n",
      "memory usage: 1.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "raop = Random_Acts_Of_Pizza(df)\n",
    "print raop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "narrative = {'Money': 'money now broke week until time last \\\n",
    "day when today tonight paid next first night after tomorrow \\\n",
    "month while account before long Friday rent buy bank still \\\n",
    "bills bills ago cash due due soon past never paycheck check \\\n",
    "spent years poor till yesterday morning dollars financial \\\n",
    "hour bill evening credit budget loan bucks deposit dollar \\\n",
    "current payed'.split(),'Job':'work job paycheck unemployment\\\n",
    "interview fired employment hired hire'.split(),'Student':'college\\\n",
    "student school roommate studying university finals semester class\\\n",
    "study project dorm tuition'.split(),'Family':'family mom wife parents\\\n",
    "mother hus- band dad son daughter father parent mum'.split(),'Craving':'friend \\\n",
    "girlfriend craving birthday boyfriend celebrate party game games movie\\\n",
    "date drunk beer celebrating invited drinks crave wasted invite'.split()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use get_dummies to encode the features as binary\n"
     ]
    }
   ],
   "source": [
    "requests = 'request_text_edit_aware'\n",
    "narrative = raop.get_narrative(col=requests,narrative=narrative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['narrative_topics'] = narrative\n",
    "df = pd.get_dummies(df,columns=['narrative_topics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "polite_words = [\n",
    "    \"please\",\"thanks\",\"thank you\",\"think\", \"thought\", \"thinking\", \"almost\",\n",
    "    \"apparent\", \"apparently\", \"appear\", \"appeared\", \"appears\", \"approximately\", \"around\",\n",
    "    \"assume\", \"assumed\", \"certain amount\", \"certain extent\", \"certain level\", \"claim\",\n",
    "    \"claimed\", \"doubt\", \"doubtful\", \"essentially\", \"estimate\",\n",
    "    \"estimated\", \"feel\", \"felt\", \"frequently\", \"from our perspective\", \"generally\", \"guess\",\n",
    "    \"in general\", \"in most cases\", \"in most instances\", \"in our view\", \"indicate\", \"indicated\",\n",
    "    \"largely\", \"likely\", \"mainly\", \"may\", \"maybe\", \"might\", \"mostly\", \"often\", \"on the whole\",\n",
    "    \"ought\", \"perhaps\", \"plausible\", \"plausibly\", \"possible\", \"possibly\", \"postulate\",\n",
    "    \"postulated\", \"presumable\", \"probable\", \"probably\", \"relatively\", \"roughly\", \"seems\",\n",
    "    \"should\", \"sometimes\", \"somewhat\", \"suggest\", \"suggested\", \"suppose\", \"suspect\", \"tend to\",\n",
    "    \"tends to\", \"typical\", \"typically\", \"uncertain\", \"uncertainly\", \"unclear\", \"unclearly\",\n",
    "    \"unlikely\", \"usually\", \"broadly\", \"tended to\", \"presumably\", \"suggests\",\n",
    "    \"from this perspective\", \"from my perspective\", \"in my view\", \"in this view\", \"in our opinion\",\n",
    "    \"in my opinion\", \"to my knowledge\", \"fairly\", \"quite\", \"rather\", \"argue\", \"argues\", \"argued\",\n",
    "    \"claims\", \"feels\", \"indicates\", \"supposed\", \"supposes\", \"suspects\", \"postulates\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of request parsed:  4040\n"
     ]
    }
   ],
   "source": [
    "politeness = raop.get_politeness(col=requests,polite_words=polite_words)\n",
    "df['politeness'] = politeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4040\n"
     ]
    }
   ],
   "source": [
    "df['request_length'] = raop.get_length(requests)\n",
    "print len(df.request_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4040\n"
     ]
    }
   ],
   "source": [
    "df['karma'] = raop.get_karma()\n",
    "print len(df.karma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4040\n"
     ]
    }
   ],
   "source": [
    "df['scores'] = raop.get_score()\n",
    "print len(df.scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4040\n"
     ]
    }
   ],
   "source": [
    "df['trust'] = raop.get_evidentiality(requests)\n",
    "print len(df.trust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4040\n"
     ]
    }
   ],
   "source": [
    "df['complexity'] = raop.get_complexity(requests)\n",
    "print len(df.complexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4040\n"
     ]
    }
   ],
   "source": [
    "df['popularity'] = raop.get_popularity('number_of_upvotes_of_request_at_retrieval' )\n",
    "print len(df.popularity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile('spellCheck.csv'):\n",
    "    df['spell_check_score'] = raop.spell_check_score(requests)\n",
    "    df['spell_check_score'].to_csv('spellCheck.csv')\n",
    "    print df.spell_check_score.head(2)\n",
    "else:\n",
    "    print 'File exists...'"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
